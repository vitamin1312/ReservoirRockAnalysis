{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ae03a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import segmentation_models_pytorch as smp\n",
    "from BlissLearn.utils import read_img, calculate_iou\n",
    "import json\n",
    "import gc\n",
    "\n",
    "from segmentation_models_pytorch.losses import DiceLoss, FocalLoss\n",
    "from BlissLearn.Core.BlissLearner import BlissLearner\n",
    "from BlissLearn.Core.BlissCallbacks.Callbacks import SegmentationMetricsCallback, PrintCriteriaCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720b4f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa87d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_file = r\"C:\\Users\\Viktor\\Documents\\IT\\ReservoirRockAnalysis\\src\\metadata\\rgb_colors.json\"\n",
    "porosty_file = r\"C:\\Users\\Viktor\\Documents\\IT\\ReservoirRockAnalysis\\src\\metadata\\porosty_info.json\"\n",
    "\n",
    "colors = load_json(colors_file)\n",
    "porosty = load_json(porosty_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdac64b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(porosty[0]['classes'])\n",
    "NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38663074",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2 \n",
    "SIZE = 1024\n",
    "\n",
    "\n",
    "path_to_train = r'C:\\Users\\Viktor\\Documents\\IT\\ReservoirRockAnalysis\\data\\train-test\\segmentation-train-data.xlsx'\n",
    "path_to_test = r'C:\\Users\\Viktor\\Documents\\IT\\ReservoirRockAnalysis\\data\\train-test\\segmentation-test-data.xlsx'\n",
    "path_to_models = r'C:\\Users\\Viktor\\Documents\\IT\\ReservoirRockAnalysis\\resources'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device_str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65250724",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_excel(path_to_train, index_col=0)\n",
    "train_df['n'] = train_df[[f'class{i}' for i in range(NUM_CLASSES)]].sum(1)\n",
    "train_df = train_df.sort_values(by='n') \n",
    "train_df.index = np.arange(len(train_df))\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d60ebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = train_df['n'].values\n",
    "sampler = WeightedRandomSampler(weights=class_counts, num_samples=len(class_counts), replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e6a325",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_excel(path_to_test, index_col=0)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00cc993",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.array([\n",
    "    [0, 0, 0],        # class 0\n",
    "    [0, 255, 0],      # class 1\n",
    "    [255, 0, 255],    # class 2\n",
    "    [255, 255, 0],    # class 3\n",
    "    [255, 0, 0],      # class 4\n",
    "    [0, 255, 255],    # class 5\n",
    "    [255, 255, 255]   # fallback for unknown class\n",
    "])\n",
    "\n",
    "def get_image_mask(mask):\n",
    "\n",
    "    # Клипим значения классов к максимально допустимым (вдруг в маске есть класс 6+)\n",
    "    mask_clipped = np.clip(mask, 0, len(colors) - 1)\n",
    "    \n",
    "    # Применяем векторно цвета\n",
    "    return colors[mask_clipped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7b4def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_train(SIZE):\n",
    "    return A.Compose(\n",
    "        transforms=[\n",
    "            A.D4(p=0.5),\n",
    "            ToTensorV2(p=1)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def transform_valid(SIZE):\n",
    "    return A.Compose(\n",
    "        transforms=[\n",
    "            A.RandomCrop(SIZE, SIZE, p=1),\n",
    "            ToTensorV2(p=1)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def transform_test(SIZE):\n",
    "    return A.Compose(\n",
    "        transforms=[\n",
    "            A.CenterCrop(SIZE, SIZE, p=1),\n",
    "            ToTensorV2(p=1)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d1510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, df, transforms):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        image = read_img(self.df.loc[index, 'image_path'])\n",
    "        mask = read_img(self.df.loc[index, 'mask_path'], rgb=False)\n",
    "\n",
    "        transformed = self.transforms(image=image, mask=mask)\n",
    "        image, mask = transformed['image'] / 255, transformed['mask']\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2e0e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = SegmentationDataset(train_df, transforms=transform_train(SIZE))\n",
    "valid_datasets = SegmentationDataset(test_df, transforms=transform_valid(SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aad2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_datasets[0]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92949287",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axs[0].imshow(x.permute(1,2,0).cpu().numpy());\n",
    "axs[1].imshow(get_image_mask(y.cpu().numpy()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa0e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    inputs, targets = zip(*batch)\n",
    "\n",
    "    inputs = torch.stack(inputs).to(dtype=torch.float, device=device)\n",
    "    targets = torch.stack(targets).to(dtype=torch.long, device=device)\n",
    "\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd8c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_datasets,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=sampler,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_datasets,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138ea215",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = next(iter(train_loader))\n",
    "len(torch.unique(yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d41686",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(\n",
    "        \"mit_b3\",\n",
    "        activation=None,\n",
    "        in_channels=3,\n",
    "        classes=NUM_CLASSES,\n",
    "        dropout=0.5,\n",
    "        decoder_attention_type='scse'\n",
    "    ).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(r\"C:\\Users\\Viktor\\Documents\\IT\\ReservoirRockAnalysis\\resources\\UnetMITSegmentationModelFT1.pkl\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ad300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# for param in model.encoder.patch_embed1.proj.parameters():\n",
    "#     param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf1c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = DiceLoss('multiclass', from_logits=True)\n",
    "\n",
    "class CombinedLoss(torch.nn.Module):\n",
    "    def __init__(self, dice_weight=0.5, focal_weight=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.dice_loss = DiceLoss('multiclass', from_logits=True)\n",
    "        self.focal_loss = FocalLoss('multiclass')\n",
    "        self.dice_weight = dice_weight\n",
    "        self.focal_weight = focal_weight\n",
    "    \n",
    "    def forward(self, outputs, targets):\n",
    "        dice_loss = self.dice_loss(outputs, targets)\n",
    "        focal_loss = self.focal_loss(outputs, targets)\n",
    "        return self.dice_weight * dice_loss + self.focal_weight * focal_loss\n",
    "\n",
    "def accuracy(yb, preds):\n",
    "    preds = torch.argmax(preds, dim=1)\n",
    "\n",
    "    return (preds == yb).float().mean().item()\n",
    "\n",
    "metrics_callback = SegmentationMetricsCallback(\n",
    "    num_classes=NUM_CLASSES,\n",
    "    common_metrics={'accuracy': accuracy},\n",
    "    class_metrics={\"iou\": calculate_iou}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdebada",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = BlissLearner(\n",
    "    model,\n",
    "    CombinedLoss(),\n",
    "    torch.optim.Adam,\n",
    "    dict(lr=1e-5),\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    batches_to_validate=146,\n",
    "    callbacks=[\n",
    "        metrics_callback,\n",
    "        PrintCriteriaCallback()\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60b11e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e774c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(learner._callback_state.epoch_train_loss['loss'])\n",
    "plt.plot(learner._callback_state.epoch_eval_loss['loss'])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d5178c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(learner._callback_state.epoch_train_criteria['iou_mean'])\n",
    "plt.plot(learner._callback_state.epoch_eval_criteria['iou_mean'])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968eaa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(learner._callback_state.epoch_train_criteria['accuracy'])\n",
    "plt.plot(learner._callback_state.epoch_eval_criteria['accuracy'])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cf76bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_inputs = torch.randn(1, 3, SIZE, SIZE).to(device)\n",
    "onnx_program = torch.onnx.export(model, example_inputs, dynamo=True)\n",
    "onnx_program.optimize()\n",
    "onnx_program.save(path_to_models + r\"\\UnetMITSegmentationModelTargetModel.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d8cfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), path_to_models + r\"\\UnetMITSegmentationModelTargetModel.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49b2940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.get_train_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ae4f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(\n",
    "        \"mit_b3\",\n",
    "        activation=None,\n",
    "        in_channels=3,\n",
    "        classes=NUM_CLASSES,\n",
    "        dropout=0.35,\n",
    "        decoder_attention_type='scse'\n",
    "    ).to(device)\n",
    "\n",
    "# model.load_state_dict(torch.load(r\"C:\\Users\\Viktor\\Documents\\IT\\ReservoirRockAnalysis\\resources\\UnetMITSegmentationModel.pkl\", weights_only=True))\n",
    "\n",
    "model.load_state_dict(torch.load(r\"C:\\Users\\Viktor\\Documents\\IT\\ReservoirRockAnalysis\\resources\\UnetMITSegmentationModelTargetModel.pkl\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ff4c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_inputs = torch.randn(1, 3, 2048, 2048).to(device)\n",
    "onnx_program = torch.onnx.export(model, example_inputs, dynamo=True)\n",
    "onnx_program.optimize()\n",
    "onnx_program.save(path_to_models + r\"\\UnetMITSegmentationModelTargetModel2k.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1bc64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datasets = SegmentationDataset(test_df, transforms=transform_valid(SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915e13c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c05389",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(test_datasets)\n",
    "# N = 10\n",
    "fig, axs = plt.subplots(N, 3, figsize=(15, 120))\n",
    "model.eval()\n",
    "\n",
    "for i, (x, y) in enumerate(test_datasets):\n",
    "    with torch.inference_mode():\n",
    "        inputs = torch.unsqueeze(x.to(device).float(), 0)\n",
    "        preds = model(inputs)[0]\n",
    "\n",
    "\n",
    "    print(preds.shape)\n",
    "    img = x.permute(1, 2, 0).cpu().numpy()\n",
    "    mask = y.cpu().numpy()\n",
    "    pred_mask = preds.argmax(dim=0).detach().cpu().numpy()\n",
    "    \n",
    "    axs[i, 0].imshow(img);\n",
    "    axs[i, 0].axis(False)\n",
    "    axs[i, 1].imshow(get_image_mask(mask));\n",
    "    axs[i, 1].axis(False)\n",
    "    axs[i, 2].imshow(get_image_mask(pred_mask));\n",
    "    axs[i, 2].axis(False)\n",
    "    if i == N - 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f131a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(r\"C:\\Users\\Viktor\\Documents\\IT\\ReservoirRockAnalysis\\resources\\UnetMITSegmentationModelFT.pkl\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a765d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 6\n",
    "N_ITER = 20\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_ious = [[] for _ in range(NUM_CLASSES)]\n",
    "all_accuracies = []\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for iteration in range(N_ITER):\n",
    "        print(f\"Validation pass {iteration + 1}/{N_ITER}...\")\n",
    "\n",
    "        for x, y_true in valid_loader:\n",
    "            x = x.to(device).float()\n",
    "            y_true = y_true.to(device).long()\n",
    "\n",
    "            preds = model(x)  # (B, C, H, W)\n",
    "            y_pred = preds.argmax(dim=1)  # (B, H, W)\n",
    "\n",
    "            # Accuracy по всей маске\n",
    "            batch_acc = (y_pred == y_true).float().mean().item()  # <-- передаём \"сырые\" logits\n",
    "            all_accuracies.append(batch_acc)\n",
    "\n",
    "            # IoU по классам\n",
    "            for class_id in range(NUM_CLASSES):\n",
    "                pred_class = (y_pred == class_id)\n",
    "                true_class = (y_true == class_id)\n",
    "                iou = calculate_iou(pred_class, true_class)\n",
    "                all_ious[class_id].append(iou)\n",
    "\n",
    "# Подсчет итоговых метрик\n",
    "mean_ious = [sum(class_ious) / len(class_ious) for class_ious in all_ious]\n",
    "mean_iou = sum(mean_ious) / NUM_CLASSES\n",
    "mean_acc = sum(all_accuracies) / len(all_accuracies)\n",
    "\n",
    "# Вывод\n",
    "print(f\"\\nAggregated TTA Validation Results over {N_ITER} iterations:\")\n",
    "for i, iou in enumerate(mean_ious):\n",
    "    print(f\" IoU class_{i}: {iou:.3f}\")\n",
    "print(f\" Mean IoU: {mean_iou:.3f}\")\n",
    "print(f\" Mean Accuracy: {mean_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2403292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
