{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import jaccard_score as iou_score\n",
    "import segmentation_models_pytorch as smp\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "from torchvision.transforms import GaussianBlur\n",
    "from utils import read_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "SIZE = 1024\n",
    "EPOCHS = 20\n",
    "N_CHANNELS = 3\n",
    "N_CLASSES = 6\n",
    "encoder = 'efficientnet-b0'\n",
    "dataset = 'imagenet'\n",
    "aux_params=dict(\n",
    "    pooling='avg',\n",
    "    dropout=0.5,\n",
    "    activation=None,\n",
    "    classes=N_CLASSES\n",
    ")\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device_str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = GaussianBlur(3, sigma=(0.01, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_train():\n",
    "    transforms = [\n",
    "        # A.SafeRotate(p=0.4),\n",
    "        A.RandomCrop(SIZE, SIZE, p=1),\n",
    "        # A.HorizontalFlip(p=0.5),\n",
    "        # A.Transpose(p=0.5),\n",
    "        # A.ColorJitter(brightness=0.33,\n",
    "        #               contrast=0.19,\n",
    "        #               saturation=0.19,\n",
    "        #               hue=(-0.05, 0.095),\n",
    "        #               p=1),\n",
    "    ]\n",
    "    return A.Compose(transforms)\n",
    "\n",
    "\n",
    "def transform_valid():\n",
    "    transforms = [\n",
    "        A.RandomCrop(SIZE+1, SIZE+1, p=1),\n",
    "        A.Resize(SIZE, SIZE, p=1),\n",
    "    ]\n",
    "    return A.Compose(transforms)\n",
    "\n",
    "\n",
    "def to_tensor():\n",
    "    transforms = [\n",
    "        ToTensorV2(p=1)\n",
    "    ]\n",
    "    return A.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "\n",
    "class PoreDataset(Dataset):\n",
    "    def __init__(self, df, transforms):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "        self.to_tensor = to_tensor()\n",
    "        self.preprocess_input = get_preprocessing_fn(encoder, pretrained='imagenet')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        image = read_img(self.df.loc[index, 'image'])\n",
    "        mask = read_img(self.df.loc[index, 'mask'], rgb=False)\n",
    "\n",
    "        transformed = self.transforms(image=image, mask=mask)\n",
    "        image, mask = transformed['image'], transformed['mask']\n",
    "\n",
    "        transformed = self.to_tensor(image=image, mask=mask)\n",
    "        image, mask = transformed['image'], transformed['mask']\n",
    "        image = blur(image)\n",
    "        image = torch.reshape(image, (SIZE, SIZE, 3))\n",
    "        image = self.preprocess_input(image)\n",
    "        image = torch.reshape(image, (3, SIZE, SIZE))\n",
    "        return image.float().to(device), mask.long().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(image):\n",
    "    image_name = image.split('/')[-1]\n",
    "    return image_name[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "images = (\n",
    "    glob(r\"C:\\Users\\Viktor\\Documents\\IT\\ReservoirRockAnalysis\\data\\Images\\Sihor\\images\\*\")\n",
    "    +\n",
    "    glob(r\"C:\\Users\\Viktor\\Documents\\IT\\ReservoirRockAnalysis\\data\\Images\\Surhar\\images\\*\")\n",
    ")\n",
    "\n",
    "masks = (\n",
    "    glob(r\"C:\\Users\\Viktor\\Documents\\IT\\ReservoirRockAnalysis\\data\\Images\\Sihor\\masks\\*\")\n",
    "    +\n",
    "    glob(r\"C:\\Users\\Viktor\\Documents\\IT\\ReservoirRockAnalysis\\data\\Images\\Surhar\\masks\\*\")\n",
    ")\n",
    "\n",
    "\n",
    "# images = sorted(list(images))[2:3]\n",
    "# masks = sorted(list(masks))[2:3]\n",
    "\n",
    "print('images count: ', len(images))\n",
    "print('masks count: ', len(masks))\n",
    "\n",
    "assert  (length := len(images)) == len(masks)\n",
    "is_valid = np.random.choice([False, True], length, p=[0.8, 0.2])\n",
    "df = pd.DataFrame({'image': images, 'mask': masks, 'is_valid': is_valid})\n",
    "\n",
    "# df.to_csv('/content/drive/MyDrive/pore segmentation/data.csv', sep=' ')\n",
    "\n",
    "train_df = df[~df['is_valid']]\n",
    "# valid_df = df[df['is_valid']]\n",
    "valid_df = train_df.copy()\n",
    "train_df.index, valid_df.index = np.arange(len(train_df)), np.arange(len(valid_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.concat([train_df for _ in range(BATCH_SIZE)])\n",
    "# train_df.index = np.arange(BATCH_SIZE)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = PoreDataset(train_df, transforms=transform_train())\n",
    "valid_datasets = PoreDataset(valid_df, transforms=transform_valid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_datasets[0]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(x.permute(1, 2, 0).cpu().numpy());\n",
    "axs[1].imshow(y.cpu().numpy());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_datasets,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    # pin_memory=True\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_datasets,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    # pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models_pytorch.losses import DiceLoss, FocalLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedLoss(torch.nn.Module):\n",
    "    def __init__(self, dice_weight=0.2, focal_weight=0.8):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.dice_loss = DiceLoss('multiclass', from_logits=True)\n",
    "        self.focal_loss = FocalLoss('multiclass', gamma=4)\n",
    "        self.dice_weight = dice_weight\n",
    "        self.focal_weight = focal_weight\n",
    "    \n",
    "    def forward(self, outputs, targets):\n",
    "        dice_loss = self.dice_loss(outputs, targets)\n",
    "        focal_loss = self.focal_loss(outputs, targets)\n",
    "        return self.dice_weight * dice_loss + self.focal_weight * focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append(\"C:/Users/Viktor/Documents/IT/ReservoirRockAnalysis/src/NeuralNetwork/\")\n",
    "from BlissLearn import BlissLearner\n",
    "# from BlissLearn import SegmentationMetricsCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Unet, self).__init__()\n",
    "        self.model = smp.Unet(\n",
    "            encoder_name=encoder,\n",
    "            encoder_weights=dataset,\n",
    "            in_channels=N_CHANNELS,\n",
    "            classes=N_CLASSES,\n",
    "            aux_params=aux_params\n",
    "        ).to(device)\n",
    "    def forward(self, x):\n",
    "       return self.model(x)[0]\n",
    "\n",
    "model = Unet()\n",
    "\n",
    "# from models import HrSegNetB64\n",
    "\n",
    "# model = HrSegNetB64(num_classes=N_CLASSES, in_channels=N_CHANNELS).to(device)\n",
    "\n",
    "# loss_fn = torch.nn.functional.cross_entropy\n",
    "# loss_fn = DiceLoss(\n",
    "#     'multiclass',\n",
    "#     from_logits=True,\n",
    "#     # alpha=0.7,\n",
    "#     # beta=0.3\n",
    "# )\n",
    "\n",
    "loss_fn = CombinedLoss()\n",
    "\n",
    "learner = BlissLearner(\n",
    "    model,\n",
    "    loss_fn,\n",
    "    torch.optim.SGD,\n",
    "    dict(lr=1e-3, momentum=0.9, weight_decay=0.0005),\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.plot_lr_finding(init_value=1e-9, final_value=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color(clls):\n",
    "    if clls == 0:\n",
    "        return [0, 0, 0]\n",
    "    elif clls == 1:\n",
    "        return [0, 255, 0]\n",
    "    elif clls == 2:\n",
    "        return [255, 0, 255]\n",
    "    elif clls == 3:\n",
    "        return [255, 255, 0]\n",
    "    elif clls == 4:\n",
    "        return [255, 0, 0]\n",
    "    elif clls == 5:\n",
    "        return [0, 255, 255]\n",
    "    else:\n",
    "        return [255, 255, 255]\n",
    "\n",
    "def get_image_mask(mask):\n",
    "    s = mask.shape\n",
    "    return np.array([get_color(pixel) for row in mask for pixel in row]).reshape(s + (3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.train_model(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.plot_learning_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('/content/drive/MyDrive/pore segmentation/manet.pkl', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.validate_n_epochs(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(xb.to(device).float())[0]\n",
    "idx = 0\n",
    "img = xb[idx].permute(1, 2, 0).cpu().numpy()\n",
    "mask = yb[idx].cpu().numpy()\n",
    "pred_mask = preds.argmax(axis=1)[idx].cpu().numpy()\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axs[0].imshow(img);\n",
    "axs[1].imshow(get_image_mask(mask));\n",
    "axs[2].imshow(get_image_mask(pred_mask));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(valid_datasets)\n",
    "fig, axs = plt.subplots(N, 3, figsize=(15, 120))\n",
    "\n",
    "for i, (x, y) in enumerate(valid_datasets):\n",
    "    preds = model(torch.unsqueeze(x.to(device).float(), 0))[0]\n",
    "    img = x.permute(1, 2, 0).cpu().numpy()\n",
    "    mask = y.cpu().numpy()\n",
    "    pred_mask = preds.argmax(axis=1).cpu().numpy()\n",
    "\n",
    "    axs[i, 0].imshow(img);\n",
    "    axs[i, 0].axis(False)\n",
    "    axs[i, 1].imshow(get_image_mask(mask));\n",
    "    axs[i, 1].axis(False)\n",
    "    axs[i, 2].imshow(get_image_mask(pred_mask[0]));\n",
    "    axs[i, 2].axis(False)\n",
    "    if i == N - 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
