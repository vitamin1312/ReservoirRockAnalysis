{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c62fd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from utils.imageIO import read_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55dbf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "SIZE = 256\n",
    "EPOCHS = 25\n",
    "\n",
    "TUNE_BATCH_SIZE = 1\n",
    "TUNE_SIZE = 1024\n",
    "TUNE_EPOCHS = 2\n",
    "\n",
    "\n",
    "path_to_train = r'C:\\Users\\Viktor\\Documents\\IT\\ReservoirRockAnalysis\\data\\train-test\\ssl-train-data.xlsx'\n",
    "path_to_test = r'C:\\Users\\Viktor\\Documents\\IT\\ReservoirRockAnalysis\\data\\train-test\\ssl-test-data.xlsx'\n",
    "path_to_models = r'C:\\Users\\Viktor\\Documents\\IT\\ReservoirRockAnalysis\\resources'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device_str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c189f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(\n",
    "        \"timm-efficientnet-b3\",\n",
    "        activation='sigmoid',\n",
    "        in_channels=1,\n",
    "        classes=3\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fcdba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(torch.randn(1, 1, SIZE, SIZE).to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3f3731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/fatemehfarnaghizadeh/pix2pix-gan\n",
    "\n",
    "class CNNBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=2):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 4, stride, bias=False, padding_mode='reflect'),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=4, features=[64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, features[0], 4, stride=2, padding_mode='reflect', padding=1),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        layers = []\n",
    "        in_channels = features[0]\n",
    "                \n",
    "        for feature in features[1:]:\n",
    "            layers.append(\n",
    "                CNNBlock(in_channels, feature, stride=1 if feature==features[-1] else 2)\n",
    "            )\n",
    "            in_channels = feature\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        self.final = nn.Conv2d(in_channels, 1, 4, stride=1, padding=1, padding_mode='reflect')\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        input = torch.cat([x, y], dim=1)\n",
    "        x = self.initial(input)\n",
    "        x = self.model(x)\n",
    "        \n",
    "        return torch.sigmoid(self.final(x))\n",
    "    \n",
    "discriminator = Discriminator().to(device)\n",
    "discriminator(torch.randn(2, 3, SIZE, SIZE).to(device), torch.randn(2, 1, SIZE, SIZE).to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d015495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_excel(path_to_train, index_col=0)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78d72e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_excel(path_to_test, index_col=0)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_train(SIZE):\n",
    "    return A.Compose(\n",
    "        transforms=[\n",
    "            A.RandomCrop(SIZE, SIZE, p=1),\n",
    "            ToTensorV2(p=1)\n",
    "        ],\n",
    "        additional_targets={'target_image': 'image'}\n",
    "    )\n",
    "\n",
    "def transform_valid(SIZE):\n",
    "    return A.Compose(\n",
    "        transforms=[\n",
    "            A.RandomCrop(SIZE, SIZE, p=1),\n",
    "            ToTensorV2(p=1)\n",
    "        ],\n",
    "        additional_targets={'target_image': 'image'}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e375681",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorizationDataset(Dataset):\n",
    "    def __init__(self, df, transforms):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        gray_image = read_img(self.df.iloc[index, 1], rgb=False)\n",
    "        image = read_img(self.df.iloc[index, 0])\n",
    "\n",
    "        transformed = self.transforms(image=gray_image, target_image=image)\n",
    "        gray_image, image = transformed['image'] / 255, transformed['target_image'] / 255\n",
    "\n",
    "        return gray_image, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b177c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = ColorizationDataset(train_df, transforms=transform_train(SIZE))\n",
    "valid_datasets = ColorizationDataset(test_df, transforms=transform_valid(SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e26bbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_datasets[0]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873f5c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axs[0].imshow(x[0].cpu().numpy(), cmap='gray');\n",
    "axs[1].imshow(y.permute(1,2,0).cpu().numpy());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d002d4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    inputs, targets = zip(*batch)\n",
    "\n",
    "    inputs = torch.stack(inputs).to(dtype=torch.float, device=device)\n",
    "    targets = torch.stack(targets).to(dtype=torch.float, device=device)\n",
    "\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4227348",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_datasets,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_datasets,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495057cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BlissLearn.BlissLearner import BlissColorizationLearner\n",
    "from BlissLearn.BlissCallbacks.Callbacks import ColorizationMetricsCallback, PrintCriteriaCallback\n",
    "from utils.metrics import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c536b2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ColorizationMetricsCallback(\n",
    "        common_generator_metrics={'MAE': nn.L1Loss()},\n",
    "        common_discriminator_metrics={'Accuracy': accuracy}\n",
    "    ),\n",
    "    PrintCriteriaCallback()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc3f999",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = BlissColorizationLearner(\n",
    "    generator=model,\n",
    "    discriminator=discriminator,\n",
    "    generator_loss_function=nn.L1Loss(),\n",
    "    discriminator_loss_function=nn.BCELoss(),\n",
    "    generator_optimizer_class=optim.Adam,\n",
    "    generator_optimizer_kwargs={'lr': 0.0002},\n",
    "    discriminator_optimizer_class=optim.Adam,\n",
    "    discriminator_optimizer_kwargs={'lr': 0.0002/1.5},\n",
    "    train_dataloader=train_loader,\n",
    "    test_dataloader=valid_loader,\n",
    "    callbacks=callbacks,\n",
    "    alpha=0.08,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae0ea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd314a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = ColorizationDataset(train_df, transforms=transform_train(TUNE_SIZE))\n",
    "valid_datasets = ColorizationDataset(test_df, transforms=transform_valid(TUNE_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecd6c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_datasets,\n",
    "    batch_size=TUNE_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_datasets,\n",
    "    batch_size=TUNE_BATCH_SIZE,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d4623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_learner = BlissColorizationLearner(\n",
    "    generator=model,\n",
    "    discriminator=discriminator,\n",
    "    generator_loss_function=nn.L1Loss(),\n",
    "    discriminator_loss_function=nn.BCELoss(),\n",
    "    generator_optimizer_class=optim.Adam,\n",
    "    generator_optimizer_kwargs={'lr': 0.0002/5},\n",
    "    discriminator_optimizer_class=optim.Adam,\n",
    "    discriminator_optimizer_kwargs={'lr': 0.0002/5},\n",
    "    train_dataloader=train_loader,\n",
    "    test_dataloader=valid_loader,\n",
    "    callbacks=callbacks,\n",
    "    alpha=0.1,\n",
    "    batches_to_validate=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3de9b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_learner.fit(TUNE_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f27f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), path_to_models + r\"\\ColorUnetEffNet.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb720da",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(discriminator.state_dict(), path_to_models + r\"\\Dics1EffNet.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9648971e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = valid_datasets[10]\n",
    "x.shape, y.shape\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    preds = model(torch.unsqueeze(x.to(device), 0))\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "axs[0].imshow(x[0].cpu().numpy(), cmap='gray');\n",
    "axs[1].imshow(y.permute(1,2,0).cpu().numpy());\n",
    "axs[2].imshow(preds[0].permute(1,2,0).cpu().numpy());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10e3ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
